# üß† AI vs Human Text Classification Tool

## üìå Project Description
This project implements a simple AI vs Human text classification tool using a pretrained transformer-based model. Given an input text, the system estimates the probability that the text is generated by AI or written by a human. An interactive Streamlit interface is provided to display prediction results together with model uncertainty indicators and system limitations, helping users interpret the output responsibly.

---

## üìä CRISP-DM Methodology

### 1Ô∏è‚É£ Business Understanding
With the increasing use of large language models, distinguishing between AI-generated and human-written text has become a relevant problem.  
The goal of this project is **not to determine authorship definitively**, but to build a **simple and interpretable tool** that provides probabilistic estimates while clearly communicating uncertainty and limitations.

**Objectives**
- Build a simple AI vs Human text classification tool  
- Provide probability-based predictions  
- Prevent over-interpretation by exposing uncertainty and system limitations  

---

### 2Ô∏è‚É£ Data Understanding
This project does **not collect or construct a custom dataset**.  
Instead, it leverages a **pretrained transformer-based model** that has already been trained on large-scale human-written and AI-generated text corpora.

**Key Considerations**
- Training data details are abstracted by the pretrained model  
- Potential biases may exist across domains, languages, and writing styles  
- Short or mixed-origin texts may reduce prediction reliability  

---

### 3Ô∏è‚É£ Data Preparation
Minimal preprocessing is applied, as the pretrained transformer model handles tokenization internally.

**Preprocessing Steps**
- Raw text input from the user  
- Automatic tokenization using the model‚Äôs tokenizer  
- No feature engineering or manual text normalization  

---

### 4Ô∏è‚É£ Modeling
A **pretrained transformer-based AI text detector** from Hugging Face is used as the core classification model.

**Model Characteristics**
- Binary classification: AI-generated vs Human-written  
- Output: probabilistic prediction (AI probability / Human probability)  
- Inference-only usage (no retraining or fine-tuning)  

**Rationale**
- Avoids dataset bias from small-scale custom data collection  
- Provides stable and reproducible inference  
- Allows focus on system design and responsible usage  

---

### 5Ô∏è‚É£ Evaluation
Instead of focusing on traditional accuracy metrics, evaluation emphasizes **prediction behavior and reliability**.

**Evaluation Strategy**
- Observe prediction stability for short vs long texts  
- Analyze confidence changes when predictions are near 50%  
- Examine edge cases such as paraphrased or mixed-style text  

**Key Observations**
- Short texts tend to produce higher uncertainty  
- Predictions near 50% indicate ambiguous textual patterns  

---

### 6Ô∏è‚É£ Deployment
The system is deployed as an interactive web application using **Streamlit**.

**Deployment Features**
- Text input interface  
- Sidebar displaying AI/Human probabilities  
- Confidence level estimation based on text length and prediction margin  
- Explicit display of uncertainty indicators  
- Clear presentation of system limitations  

---

## üß† Model Uncertainty & Limitations

### Model Uncertainty
Prediction confidence is estimated using:
- Text length (word count)  
- Prediction margin (distance from 50%)  

Confidence levels are categorized as:
- üü¢ High Confidence  
- üü° Medium Confidence  
- üî¥ Low Confidence  

---

### System Limitations
- Predictions are probabilistic, not definitive judgments  
- Short texts may lead to unreliable results  
- Mixed human-AI writing cannot be accurately detected  
- Results may vary across domains and languages  

---

## üõ†Ô∏è Technologies Used
- Python  
- Hugging Face Transformers  
- PyTorch (inference only)  
- Streamlit  

---

## üöÄ How to Run

```bash
pip install streamlit transformers torch sentencepiece
streamlit run app.py

